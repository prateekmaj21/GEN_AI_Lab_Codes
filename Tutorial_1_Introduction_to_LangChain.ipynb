{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5f8eaa5e-7091-47d1-b033-8c52e4327054",
      "metadata": {
        "id": "5f8eaa5e-7091-47d1-b033-8c52e4327054"
      },
      "source": [
        "Models, Prompts, Parsers, Memory and Chains - https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf3368b",
      "metadata": {
        "id": "3cf3368b"
      },
      "source": [
        "### Initial setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af3e43dd",
      "metadata": {
        "id": "af3e43dd"
      },
      "source": [
        "#### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4b7d1870",
      "metadata": {
        "id": "4b7d1870"
      },
      "outputs": [],
      "source": [
        "# # create virtual environment\n",
        "# %python -m venv python_venv\n",
        "# %pip install --quiet langchain-community==0.3.0 langgraph==0.2.22 langchain-groq==0.2.0 python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain-community==0.3.0 langgraph==0.2.22 langchain-groq==0.2.0 python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcDB7bDw8LLD",
        "outputId": "745c37b3-9645-45c0-a0bf-fc2efe24ee32"
      },
      "id": "mcDB7bDw8LLD",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community==0.3.0\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting langgraph==0.2.22\n",
            "  Downloading langgraph-0.2.22-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-groq==0.2.0\n",
            "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.0) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.0) (3.11.11)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.0)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.0) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.0) (0.3.29)\n",
            "Collecting langsmith<0.2.0,>=0.1.112 (from langchain-community==0.3.0)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.0) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.0)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.3.0) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-community==0.3.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph==0.2.22)\n",
            "  Downloading langgraph_checkpoint-1.0.12-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq==0.2.0)\n",
            "  Downloading groq-0.15.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq==0.2.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq==0.2.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq==0.2.0) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq==0.2.0) (2.10.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq==0.2.0) (4.12.2)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community==0.3.0) (0.3.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community==0.3.0) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community==0.3.0) (24.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<2.0.0,>=1.0.2->langgraph==0.2.22) (1.1.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community==0.3.0) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community==0.3.0) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.3.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.3.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.3.0) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.0) (3.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq==0.2.0) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq==0.2.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq==0.2.0) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-community==0.3.0) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq==0.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq==0.2.0) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.22-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.15.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-1.0.12-py3-none-any.whl (17 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m908.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tenacity, python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, langsmith, groq, dataclasses-json, langgraph-checkpoint, langchain-groq, langgraph, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.2.10\n",
            "    Uninstalling langsmith-0.2.10:\n",
            "      Successfully uninstalled langsmith-0.2.10\n",
            "Successfully installed dataclasses-json-0.6.7 groq-0.15.0 langchain-community-0.3.0 langchain-groq-0.2.0 langgraph-0.2.22 langgraph-checkpoint-1.0.12 langsmith-0.1.147 marshmallow-3.25.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 tenacity-8.5.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f488b51",
      "metadata": {
        "id": "9f488b51"
      },
      "source": [
        "#### Set API key for Groq\n",
        "[create API key for Groq](https://console.groq.com/keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b73bcaf4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b73bcaf4",
        "outputId": "3c965e2e-ab82-4613-9aac-d374f074a9ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GROQ API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os, json, re, getpass\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(\".env\", override=True)\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"GROQ API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31b9342",
      "metadata": {
        "id": "e31b9342"
      },
      "source": [
        "### LangChain Components"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d44e67",
      "metadata": {
        "id": "71d44e67"
      },
      "source": [
        "#### LLM / ChatModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f4df3c94",
      "metadata": {
        "id": "f4df3c94"
      },
      "outputs": [],
      "source": [
        "# LLM\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "model_id = \"llama3-8b-8192\" #llama3-8b-8192, llama-3.1-8b-instant, llama3-groq-8b-8192-tool-use-preview, llama3-groq-70b-8192-tool-use-preview\n",
        "llm = ChatGroq(model_name=model_id, temperature=0, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4d8fd4ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d8fd4ce",
        "outputId": "3508eaaa-2e71-4860-998e-c1ede58c8f3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"ECG stands for Electrocardiogram, which is a non-invasive medical test that records the electrical activity of the heart. It is a simple, painless, and widely used diagnostic tool to evaluate the heart's rhythm, rate, and electrical activity.\\n\\nDuring an ECG, small electrodes are placed on the skin of the chest, arms, and legs to detect the electrical impulses that control the heartbeat. These impulses are then recorded on a graph, known as an electrocardiogram, which shows the heart's electrical activity over time.\\n\\nAn ECG can help diagnose a variety of heart-related conditions, including:\\n\\n1. Arrhythmias (abnormal heart rhythms)\\n2. Heart attacks (myocardial infarction)\\n3. Heart failure\\n4. Coronary artery disease\\n5. Cardiac hypertrophy (enlargement of the heart)\\n6. Electrolyte imbalances\\n7. Medication side effects\\n\\nThere are different types of ECGs, including:\\n\\n1. Resting ECG: Performed while the patient is at rest.\\n2. Stress ECG (also known as treadmill test or exercise ECG): Performed while the patient is exercising on a treadmill or stationary bike.\\n3. Holter monitor ECG: A portable device that records the heart's activity over a 24-hour period.\\n4. Event monitor ECG: A portable device that records the heart's activity for a short period of time (usually 30 days) and can be triggered by the patient when they experience symptoms.\\n\\nOverall, an ECG is a valuable diagnostic tool that helps healthcare providers diagnose and manage heart-related conditions.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 331, 'prompt_tokens': 15, 'total_tokens': 346, 'completion_time': 0.275833333, 'prompt_time': 0.002403615, 'queue_time': 0.018030863999999997, 'total_time': 0.278236948}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None}, id='run-9d22d029-c09e-4818-9da2-c4e3bb6c591c-0', usage_metadata={'input_tokens': 15, 'output_tokens': 331, 'total_tokens': 346})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "llm_response = llm.invoke(\"what is ECG?\")\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response = llm.invoke(\"What is samsung?\")\n",
        "llm_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzu2g9SZ9tUJ",
        "outputId": "3931adda-13ab-4f51-a7ba-d5cf1812806e"
      },
      "id": "nzu2g9SZ9tUJ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Samsung is a South Korean multinational conglomerate company that produces a wide range of electronics, semiconductors, and other products. The company was founded in 1938 by Lee Byung-chul as a trading company, and it has since grown to become one of the largest and most successful technology companies in the world.\\n\\nSamsung is perhaps best known for its smartphones, which are among the most popular and highly-regarded in the world. The company's Galaxy series of smartphones has been a huge success, and it has also developed a range of other mobile devices, including tablets, wearables, and smartwatches.\\n\\nIn addition to its mobile devices, Samsung also produces a wide range of other products, including:\\n\\n1. TVs: Samsung is a major player in the global TV market, and its QLED and SUHD TVs are highly regarded for their picture quality and features.\\n2. Home appliances: Samsung produces a range of home appliances, including refrigerators, washing machines, air conditioners, and more.\\n3. Semiconductors: Samsung is a leading manufacturer of semiconductors, which are used in a wide range of electronic devices, including smartphones, laptops, and servers.\\n4. Computers: Samsung produces a range of computers, including laptops and desktops.\\n5. Medical equipment: Samsung produces a range of medical equipment, including MRI and CT scanners, as well as diagnostic equipment and medical imaging systems.\\n6. Network systems: Samsung produces a range of network systems, including routers, switches, and other networking equipment.\\n\\nSamsung is headquartered in Seoul, South Korea, and it has operations in over 80 countries around the world. The company is known for its innovative products and services, as well as its commitment to research and development.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 353, 'prompt_tokens': 14, 'total_tokens': 367, 'completion_time': 0.294166667, 'prompt_time': 0.001625193, 'queue_time': 0.019372375, 'total_time': 0.29579186}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-05adaa05-d1d6-45c1-9f46-b1f56fc4962e-0', usage_metadata={'input_tokens': 14, 'output_tokens': 353, 'total_tokens': 367})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "498e9f67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "498e9f67",
        "outputId": "3f360278-3ae8-4de6-f281-6e4f31cc8112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of response <class 'langchain_core.messages.ai.AIMessage'>\n"
          ]
        }
      ],
      "source": [
        "print(\"type of response\", type(llm_response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "edc8d4ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "edc8d4ad",
        "outputId": "4982273b-651d-4cd2-9dcb-a438521448af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'input_tokens': 14, 'output_tokens': 353, 'total_tokens': 367}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# print(llm_response.content)\n",
        "# display(llm_response.response_metadata)\n",
        "display(llm_response.usage_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "abff1d02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abff1d02",
        "outputId": "10e03c4f-6ddd-41fc-d998-b4bb86a082e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the corrected text:\n",
            "\n",
            "\"Hey, could you please send me that report by tomorrow? Thank you.\"\n",
            "\n",
            "I corrected the following errors:\n",
            "\n",
            "* \"hey\" to \"Hey\" (capitalization)\n",
            "* \"can\" to \"could\" (correct verb usage)\n",
            "* \"thx\" to \"Thank you\" (correct abbreviation and punctuation)\n",
            "* Added a question mark at the end of the sentence to make it a proper question.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Detect and correct all spelling, grammatical, and punctuation errors in the provided text.\\\n",
        "                  Ensure proper sentence structure, clarity, and readability.\\\n",
        "                  Retain the core message of the original text while making the necessary corrections\"),\n",
        "    HumanMessage(content=\"hey can you send me that report by tomorrow thx\"),\n",
        "]\n",
        "\n",
        "ai_response = llm.invoke(messages)\n",
        "print(ai_response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"Summarize the text and give in points.\\\n",
        "                  Ensure proper sentence structure, clarity, and readability.\\\n",
        "                  Retain the core message of the original text while making the necessary corrections\"),\n",
        "    HumanMessage(content=\"Throughout its history, the company has been noted for its continued participation in racing, especially in Formula One, where its team, Scuderia Ferrari, is the series' single oldest and most successful. Scuderia Ferrari has raced since 1929, first in Grand Prix events and later in Formula One, where it holds many records. Historically, Ferrari was also highly active in sports car racing, where its cars took many wins in races such as the Mille Miglia, Targa Florio and 24 Hours of Le Mans, as well as several overall victories in the World Sportscar Championship. Scuderia Ferrari fans, commonly called tifosi, are known for their passion and loyalty to the team.\"),\n",
        "]\n",
        "\n",
        "ai_response = llm.invoke(messages)\n",
        "print(ai_response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k5WvXPmA7nq",
        "outputId": "47ad2051-7ae8-4f94-de0c-f58310399eeb"
      },
      "id": "9k5WvXPmA7nq",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a summary of the text in points:\n",
            "\n",
            "**Ferrari's Racing History**\n",
            "\n",
            "* Ferrari has a long history of participation in racing, particularly in Formula One.\n",
            "* Scuderia Ferrari, the company's racing team, is the oldest and most successful in the series, dating back to 1929.\n",
            "* The team has competed in both Grand Prix events and Formula One, holding many records.\n",
            "* Ferrari was also highly active in sports car racing, winning numerous races, including:\n",
            "\t+ Mille Miglia\n",
            "\t+ Targa Florio\n",
            "\t+ 24 Hours of Le Mans\n",
            "\t+ World Sportscar Championship\n",
            "* Ferrari fans, known as tifosi, are known for their passion and loyalty to the team.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1b610c52",
      "metadata": {
        "id": "1b610c52"
      },
      "outputs": [],
      "source": [
        "# followup conversation\n",
        "messages.append(ai_response)\n",
        "messages.append(HumanMessage(content=\"can you make the tone a bit informal\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b988b6ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b988b6ae",
        "outputId": "707a93dd-f4d1-45a6-bbec-489496cbb026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a summary of the text in points with a more informal tone:\n",
            "\n",
            "**Ferrari's Racing Roots**\n",
            "\n",
            "* Ferrari's been racing for ages, and Formula One is where they've made their mark.\n",
            "* Their team, Scuderia Ferrari, is the oldest and most successful in the series, dating back to 1929.\n",
            "* They've been killing it in both Grand Prix events and Formula One, breaking records left and right.\n",
            "* But it's not just F1 - Ferrari's also had a blast in sports car racing, taking home wins in:\n",
            "\t+ Mille Miglia\n",
            "\t+ Targa Florio\n",
            "\t+ 24 Hours of Le Mans\n",
            "\t+ World Sportscar Championship\n",
            "* And let's not forget the fans - the tifosi are some of the most passionate and loyal out there!\n"
          ]
        }
      ],
      "source": [
        "ai_response = llm.invoke(messages)\n",
        "print(ai_response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explain concept of context length here**\n",
        "\n",
        "Context length is the maximum number of tokens a large language model (LLM) can process at once. It's similar to an LLM's working memory, and determines how much information it can consider when generating responses."
      ],
      "metadata": {
        "id": "uteYH7odBskV"
      },
      "id": "uteYH7odBskV"
    },
    {
      "cell_type": "markdown",
      "id": "ab8f9d09",
      "metadata": {
        "id": "ab8f9d09"
      },
      "source": [
        "#### Output Parsers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7b2bb113",
      "metadata": {
        "id": "7b2bb113"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
        "\n",
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46cc74a4",
      "metadata": {
        "id": "46cc74a4"
      },
      "source": [
        "*StrOutputParser* is a runnable object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d4d28206",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "d4d28206",
        "outputId": "56676539-9171-43f9-9003-4dfbbd7616a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Here's a summary of the text in points with a more informal tone:\\n\\n**Ferrari's Racing Roots**\\n\\n* Ferrari's been racing for ages, and Formula One is where they've made their mark.\\n* Their team, Scuderia Ferrari, is the oldest and most successful in the series, dating back to 1929.\\n* They've been killing it in both Grand Prix events and Formula One, breaking records left and right.\\n* But it's not just F1 - Ferrari's also had a blast in sports car racing, taking home wins in:\\n\\t+ Mille Miglia\\n\\t+ Targa Florio\\n\\t+ 24 Hours of Le Mans\\n\\t+ World Sportscar Championship\\n* And let's not forget the fans - the tifosi are some of the most passionate and loyal out there!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "result = llm.invoke(messages)\n",
        "\n",
        "parser.invoke(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6a422868",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a422868",
        "outputId": "81363b65-c06f-4831-a573-aa4921997d50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clarity': 'clear',\n",
              " 'grammar_quality': 'correct',\n",
              " 'tone': 'informal',\n",
              " 'suggestions': \"Consider adding a specific deadline or a polite phrase to make the request more formal, e.g., 'Could you please send me the report by tomorrow at the latest?'\"}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"\"\"You are an expert in writing analysis. You will receive a message from a user, and your job is to evaluate the text based on the following attributes:\n",
        "1. clarity: Is the message clear, or unclear?\n",
        "2. grammar_quality: Are there any grammatical issues? Possible values: correct, minor issues, major issues.\n",
        "3. tone: Analyze whether the tone is neutral, formal, or informal.\n",
        "4. suggestions: Offer brief improvement suggestions for clarity, grammar, or tone.\n",
        "\n",
        "Return a structured JSON object with these four attributes.\"\"\"),\n",
        "    HumanMessage(content=\"Hey, could you please send me that report by tomorrow? Thank you.\")\n",
        "]\n",
        "response = llm.invoke(messages)\n",
        "\n",
        "json_response = JsonOutputParser().invoke(response)\n",
        "json_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2764627d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2764627d",
        "outputId": "e1bc8fa2-026e-4c71-be1a-783b28d4a6f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the analysis of the text:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"clarity\": \"clear\",\n",
            "  \"grammar_quality\": \"correct\",\n",
            "  \"tone\": \"informal\",\n",
            "  \"suggestions\": \"Consider adding a specific deadline or a polite phrase to make the request more formal, e.g., 'Could you please send me the report by tomorrow at the latest?'\"\n",
            "}\n",
            "```\n",
            "\n",
            "Let me know if you have any questions or if you'd like me to elaborate on any of these points!\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "001ac77b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "001ac77b",
        "outputId": "dd0d42f6-46d9-4d0c-90b4-49f3dd8322ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'clear'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "json_response['clarity']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9bd4adf",
      "metadata": {
        "id": "d9bd4adf"
      },
      "source": [
        "#### Chain (LCEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b49e8f26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b49e8f26",
        "outputId": "93f2ffb3-1731-4dc0-f091-43645824d87e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clarity': 'clear',\n",
              " 'grammar_quality': 'correct',\n",
              " 'tone': 'informal',\n",
              " 'suggestions': \"Consider adding a specific deadline or a polite phrase to make the request more formal, e.g., 'Could you please send me the report by tomorrow at the latest?'\"}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "chain = llm | JsonOutputParser()\n",
        "\n",
        "chain.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "755c72bd",
      "metadata": {
        "id": "755c72bd"
      },
      "source": [
        "#### PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f421e4a3",
      "metadata": {
        "id": "f421e4a3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "system_message_template = \"\"\"Detect and correct all spelling, grammatical, and punctuation errors in the provided text.\n",
        "Ensure proper sentence structure, clarity, and readability.\n",
        "\n",
        "Tone Adjustment: {tone}\n",
        "\n",
        "Communication Style: {communication_style}\n",
        "\n",
        "Retain the core message of the original text while making the necessary corrections and tone adjustments.\n",
        "Suggest appropriate phrasing and formatting based on the tone and communication style.\"\"\"\n",
        "template = ChatPromptTemplate([\n",
        "    (\"system\", system_message_template),\n",
        "    (\"human\", \"{user_input}\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ca2144f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca2144f8",
        "outputId": "af0b501b-c34d-43c7-980b-0ab2f4fc75b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['communication_style', 'tone', 'user_input']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "template.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "3c21138e",
      "metadata": {
        "id": "3c21138e"
      },
      "outputs": [],
      "source": [
        "tone_map = {\n",
        "    \"Formal\": \"Rewrite the message in a professional, polite, and structured manner. Suitable for business emails, official reports, or any context requiring formality and respect.\",\n",
        "    \"Informal\": \"Rewrite in a casual, friendly, and conversational style. Appropriate for personal communications, friendly chats, or informal emails.\",\n",
        "    \"Neutral\": \"Rewrite in a balanced tone that is neither overly formal nor too casual. Suitable for most general communications where a middle-ground tone is required.\"\n",
        "}\n",
        "communication_style_map = {\n",
        "    \"Email\": \"Messages should be clear, structured, and formal or neutral depending on the context. Introductions, conclusions, and appropriate sign-offs should be added if missing.\",\n",
        "    \"General\": \"This covers most forms of communication and will aim for clarity and coherence. The tone can vary as per the user's choice.\",\n",
        "    \"Instant Messaging\": \"Focus on brevity, clarity, and informality, using conversational phrasing suitable for quick back-and-forth exchanges.\",\n",
        "    \"Business Instant Messaging\": \"Maintain a professional but conversational tone. Messages should be concise and efficient, avoiding unnecessary formalities but keeping the language respectful.\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "423f262c",
      "metadata": {
        "id": "423f262c"
      },
      "outputs": [],
      "source": [
        "proof_read_chain = template | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "69f84976",
      "metadata": {
        "id": "69f84976"
      },
      "outputs": [],
      "source": [
        "# proof_read_chain.input_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cef8565b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cef8565b",
        "outputId": "dc91b9a9-b35a-485e-d15c-973add50042b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a rewritten version of your message in a professional, polite, and structured tone:\n",
            "\n",
            "\"Dear [Recipient],\n",
            "\n",
            "I would greatly appreciate it if you could provide me with the requested data by the end of the day (EOD) today. Could you please ensure that the data is sent to me in a timely manner so that I can review and utilize it accordingly?\n",
            "\n",
            "Thank you for your prompt attention to this matter.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\"\n",
            "\n",
            "I made the following changes to the original message:\n",
            "\n",
            "* Added a formal greeting and sign-off\n",
            "* Changed the tone to be polite and professional\n",
            "* Structured the message to be clear and concise\n",
            "* Retained the core message of the original text while making necessary corrections\n"
          ]
        }
      ],
      "source": [
        "tone = \"Formal\" # Formal, Informal, Neutral\n",
        "communication_style = \"Email\" # Email, General, Instant Messaging, Business Instant Messaging\n",
        "user_input = \"\"\"Can u send me the data by eod pls?\"\"\"\n",
        "\n",
        "chain_output = proof_read_chain.invoke(dict(\n",
        "    tone=tone_map[tone],\n",
        "    communication_style = communication_style_map[communication_style],\n",
        "    user_input = user_input\n",
        "))\n",
        "print(chain_output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tone = \"Informal\" # Formal, Informal, Neutral\n",
        "communication_style = \"General\" # Email, General, Instant Messaging, Business Instant Messaging\n",
        "user_input = \"\"\"Can u send me the data by eod pls?\"\"\"\n",
        "\n",
        "chain_output = proof_read_chain.invoke(dict(\n",
        "    tone=tone_map[tone],\n",
        "    communication_style = communication_style_map[communication_style],\n",
        "    user_input = user_input\n",
        "))\n",
        "print(chain_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixZCOnmqrQdO",
        "outputId": "68bce77f-00df-4efe-8de7-30fc51fcf62e"
      },
      "id": "ixZCOnmqrQdO",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a rewritten version of your request in a casual, friendly, and conversational tone:\n",
            "\n",
            "\"Hey, could you please send me the data by the end of the day (EOD)? I'd really appreciate it if you could get it to me on time. Thanks so much!\"\n",
            "\n",
            "I corrected the following errors:\n",
            "\n",
            "* \"u\" to \"you\" (informal text often uses abbreviations, but in a friendly tone, it's better to use the full word)\n",
            "* Added a polite phrase (\"I'd really appreciate it\") to make the request more considerate\n",
            "* Changed the sentence structure to make it more conversational and easy to read\n",
            "* Added a friendly closing (\"Thanks so much!\") to maintain a positive tone\n",
            "\n",
            "Let me know if you'd like me to make any further adjustments!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}